---
topic: Machine Learning
type: Technical
tags:
title: >
  Artificial Neurogenesis for Adaptive Continual Learning
speaker: Karthik Charan Raghunathan
institution: University of Zurich
webpage:  https://scholar.google.com/citations?user=7wKYVjkAAAAJ&hl=en
date: 2026-02-11 14:00
venue: MCCREA 1-16 
link: https://teams.microsoft.com/l/meetup-join/19%3ameeting_NGRhZjQ1OGMtNzA4Mi00MWMxLWE1ODEtNzJjNmEwZjBkZTg1%40thread.v2/0?context=%7b%22Tid%22%3a%222efd699a-1922-4e69-b601-108008d28a2e%22%2c%22Oid%22%3a%229c6a898b-86f6-4344-8f36-27129ffe3748%22%7d 
recording: https://rhul-my.sharepoint.com/:v:/g/personal/anand_subramoney_rhul_ac_uk/IQDUjBOdbrWjRoEN4rWRGvgZAY_7XsHFmi0LSAxOUb-vm6Y?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJTdHJlYW1XZWJBcHAiLCJyZWZlcnJhbFZpZXciOiJTaGFyZURpYWxvZy1MaW5rIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXcifX0%3D&e=G86ei4 
bio: >
  Karthik is a second-year PhD student in NeuroAI (Neuro-inspired Artificial Intelligence) at the Institute of Neuroinformatics, a joint institute of ETH & UZH Zurich. He works in the Emerging Intelligent Substrates group, supervised by Prof. Dr. Melika Payvand.
  Karthik holds a Bachelor's in Computer Science Engineering (India) and a Master's in Cognitive Neuroscience from the University of Groningen (The Netherlands). His current research is dedicated to leveraging biological principles to fundamentally improve mechanisms for sequential knowledge accumulation (Continual Learning) in artificial systems, aiming to create more efficient and robust intelligent substrates.
abstract: >
  A key challenge for artificial intelligence is continual learning, where models must acquire new knowledge sequentially without catastrophically forgetting previously learned tasks. Existing solutions often propose a fixed number of future tasks to pre-define a static network size, leading to significant over-parameterization and inefficiency in real-world scenarios. In this talk I will introduce a dynamic framework for continual learning that enables models to learn without any apriori knowledge of the tasks it will face. We demonstrate that our approach successfully learns continual classification benchmarks, autonomously discovering network architectures that matches performance of static models of same size.
---
